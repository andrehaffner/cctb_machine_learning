{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [0.25, 0.75, 0.1, 0.9],\n",
        "    [0.1, 0.3, 0.8, 0.4],\n",
        "    [0.7, 0.5, 0.2, 0.6],\n",
        "    [0.9, 0.2, 0.3, 0.1],\n",
        "    [0.4, 0.6, 0.7, 0.3],\n",
        "    [0.6, 0.9, 0.8, 0.2],\n",
        "    [0.3, 0.4, 0.5, 0.7],\n",
        "    [0.8, 0.1, 0.6, 0.5],\n",
        "    [0.2, 0.7, 0.9, 0.4],\n",
        "    [0.5, 0.8, 0.4, 0.6],\n",
        "    [0.9, 0.3, 0.1, 0.7],\n",
        "    [0.1, 0.2, 0.7, 0.8],\n",
        "    [0.7, 0.6, 0.5, 0.3],\n",
        "    [0.4, 0.9, 0.3, 0.2],\n",
        "    [0.8, 0.5, 0.6, 0.1],\n",
        "    [0.3, 0.7, 0.4, 0.9],\n",
        "    [0.6, 0.4, 0.9, 0.5],\n",
        "    [0.2, 0.1, 0.8, 0.7],\n",
        "    [0.5, 0.3, 0.6, 0.4],\n",
        "    [0.9, 0.7, 0.2, 0.3]\n",
        "])\n",
        "\n",
        "y = np.array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n"
      ],
      "metadata": {
        "id": "6pFZnvs98WJO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Gx6FNB3L8iux"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, n_trees, X, y,  base_model = DecisionTree, sample_percentage = 0.4, feature_percentage = 0.5):\n",
        "        self.trees = [base_model() for i in range(n_trees)]\n",
        "        # each tree has its own (X,y) tuple as training dataset. \n",
        "        self.sample_percentage = sample_percentage\n",
        "        self.feature_percentage = feature_percentage\n",
        "        self.subsets = [self._bootstrap_sample(X,y) for i in range(n_trees)]\n",
        "\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        # sampling the records\n",
        "        sample_size = int(len(X) * self.sample_percentage)\n",
        "        random_indices = np.random.choice(len(X), size=sample_size, replace=True)\n",
        "        sample_X = X[random_indices]\n",
        "        sample_y = y[random_indices]\n",
        "        # sampling the features.\n",
        "        feature_indices = np.arange(X.shape[1])\n",
        "        np.random.shuffle(feature_indices)\n",
        "        feature_indices_sample = feature_indices[:2]\n",
        "        sample_X = sample_X[:, feature_indices_sample]\n",
        "        return (sample_X, sample_y, feature_indices_sample)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # fit each tree using the X and y.\n",
        "        for idx, tree in enumerate(self.trees):\n",
        "            sample_X, sample_y = self.subsets[idx][0], self.subsets[idx][1]\n",
        "            tree.fit(sample_X, sample_y)\n",
        "\n",
        "    def predict(self, X): # this X here is N by 4. \n",
        "        # step 1: each tree predicts\n",
        "        predictions = []\n",
        "        for idx, tree in enumerate(self.trees):\n",
        "            feature_indices = self.subsets[idx][2]\n",
        "            sample_X = X[:, feature_indices]\n",
        "            pred_y = tree.predict(sample_X)\n",
        "            predictions.append(pred_y)\n",
        "        \n",
        "        # step 2: vote\n",
        "        final_prediction = []\n",
        "        for record_idx in range(X.shape[0]):\n",
        "            opinions = [pred[record_idx] for pred in predictions]\n",
        "            # taking each tree's first opinion\n",
        "            unique_values, counts = np.unique(opinions, return_counts=True)\n",
        "            max_count = np.max(counts)\n",
        "            final_opinion = unique_values[counts == max_count]\n",
        "            final_prediction.append(final_opinion)\n",
        "        \n",
        "        return predictions, final_prediction\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "lr_rf = RandomForest(7, X, y, base_model = LogisticRegression)\n",
        "real_rf = RandomForest(7, X, y, base_model = LogisticRegression)\n",
        "svm_rf = RandomForest(7, X, y, base_model = SVC)"
      ],
      "metadata": {
        "id": "rS-dBzRj4BGt"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}